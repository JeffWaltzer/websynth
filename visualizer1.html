```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio-Reactive Plasma Generator</title>
    <!-- existing head content -->
    <style>
        .toolbar {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            background: #333;
            padding: 2px;
            box-sizing: border-box;
            text-align: center;
            z-index: 1000;
        }
        .toolbar button {
            background: #555;
            color: white;
            border: 1px solid #888;
            border-radius: 3px;
            padding: 1px 4px;
            margin: 1px;
            cursor: pointer;
            font-size: 12px;
        }
        .toolbar button:disabled {
            background: #777;
            color: #ccc;
            cursor: default;
        }
    </style>
    <style>
        /* General Setup */
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #000;
            font-family: 'Inter', sans-serif;
            color: #fff;
        }

        /* Canvas Full Screen (Covers entire viewport) */
        #plasmaCanvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background-color: black;
            image-rendering: pixelated;
        }

        /* Overlay & Controls */
        #overlay {
            position: fixed;
            z-index: 100;
            padding: 30px;
            text-align: center;
            background: rgba(0, 0, 0, 0.85); /* Slightly darker overlay */
            border-radius: 12px;
            backdrop-filter: blur(5px);
            box-shadow: 0 0 40px rgba(255, 255, 255, 0.3);
            transition: opacity 0.5s;
        }

        #loadingText {
            font-size: 1.5rem;
            margin-bottom: 20px;
            color: #ffcc00;
        }

        #autoRecordControl {
            margin-bottom: 25px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #autoRecord {
            transform: scale(1.5);
            margin-right: 10px;
        }

        .control-group {
            margin-bottom: 20px;
            padding: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 8px;
        }

        .control-group h3 {
            margin-top: 0;
            color: #ccc;
        }

        .button-style {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 8px;
            transition: background-color 0.3s, transform 0.1s, box-shadow 0.3s;
            width: 90%;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.4);
        }

        .button-style:hover {
            background-color: #45a049;
            box-shadow: 0 6px 20px rgba(76, 175, 80, 0.5);
        }

        .button-style:active {
            transform: scale(0.98);
        }

        #fileInput {
            display: none;
        }

        #loadFromFileButton {
            background-color: #008CBA; /* Blue for file load */
        }
        #loadFromFileButton:hover {
            background-color: #007bb5;
            box-shadow: 0 6px 20px rgba(0, 140, 186, 0.5);
        }

        .error {
            color: #ff4d4d;
            font-weight: bold;
            margin-top: 10px;
        }

        /* Message box styling for clarity */
        #message {
            text-align: left;
            padding: 15px;
            background-color: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
        }

        /* Fullscreen Button Style */
        #fullscreenButton {
            position: fixed;
            bottom: 20px;
            right: 20px;
            z-index: 60;
            background-color: rgba(30, 30, 30, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            width: 44px;
            height: 44px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease-in-out, background-color 0.2s, box-shadow 0.2s;
        }

        #fullscreenButton:hover {
            background-color: rgba(50, 50, 50, 0.9);
            box-shadow: 0 0 10px rgba(255, 255, 255, 0.5);
        }

        #fullscreenButton svg {
            fill: white;
            width: 24px;
            height: 24px;
        }

        /* Record Button Style */
        #recordContainer {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 60;
            display: none;
            flex-direction: column;
            align-items: center;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease-in-out;
        }

        #recordButton {
            background-color: #f44336; /* Red */
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: bold;
            cursor: pointer;
            border: none;
            transition: background-color 0.3s, opacity 0.3s;
        }

        #recordButton.recording {
            background-color: #ff0000;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 0, 0, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 0, 0, 0); }
        }

        #recordingStatus {
            margin-top: 5px;
            color: #f44336;
            font-size: 0.9rem;
            font-weight: bold;
            opacity: 0;
            transition: opacity 0.3s;
        }
        /* Stop Visualizer Button Specific Style */
        #stopVisualizerButton {
            background-color: #6c757d;
            margin-top: 10px;
            width: 100%;
            padding: 10px 20px;
            font-size: 1rem;
        }
        #stopVisualizerButton:hover {
            background-color: #5a6268;
            box-shadow: 0 6px 20px rgba(108, 117, 125, 0.5);
        }
    </style>
</head>
<body>
<div class="toolbar">
    <button onclick="window.location.href='index.html'">Home</button>
    <button onclick="window.location.href='berlin.html'">Berlin</button>
    <button onclick="window.location.href='chords.html'">Chords</button>
    <button onclick="window.location.href='delay.html'">Delay</button>
    <button onclick="window.location.href='karplus.html'">Karplus</button>
    <button onclick="window.location.href='polychain.html'">Polychain</button>
    <button onclick="window.location.href='pondviz.html'">Pond</button>
    <button onclick="window.location.href='rhythm.html'">Rhythm</button>
    <button onclick="window.location.href='starfield.html'">Starfield</button>
    <button disabled>Viz 1</button>
</div>
<!-- rest of body content -->

<canvas id="plasmaCanvas"></canvas>


<button id="fullscreenButton" title="Toggle Fullscreen">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>
    </svg>
</button>

<div id="recordContainer">
    <button id="recordButton">START RECORDING (WebM)</button>
    <div id="recordingStatus">Recording...</div>
    <button id="stopVisualizerButton" class="button-style">STOP VISUALIZER</button>
</div>


<div id="overlay">
    <div id="loadingText">
        Choose your audio source and visual effect to start.
    </div>

    <div class="control-group">
        <h3>Overlay Effects (Select one or more)</h3>
        <div id="effectCheckboxes" style="text-align: left; display: flex; flex-direction: column; gap: 10px; padding: 5px;">

            <label title="Concentric circles that deform and ripple like an oscilloscope based on mid-high frequencies." style="cursor: pointer;">
                <input type="checkbox" id="toggleCircles" data-effect="circles" checked style="transform: scale(1.1); margin-right: 8px;">
                Concentric Circles (Radial Waves)
            </label>

            <label title="A central, spinning ring of bars representing the full audio spectrum." style="cursor: pointer;">
                <input type="checkbox" id="toggleAnalyzer" data-effect="analyzer" checked style="transform: scale(1.1); margin-right: 8px;">
                Radial Analyzer (Spectrograph)
            </label>

            <label title="Bass-driven grid of vertical bars on the top and bottom edges that pulse with the rhythm." style="cursor: pointer;">
                <input type="checkbox" id="toggleHgrid" data-effect="hgrid" style="transform: scale(1.1); margin-right: 8px;">
                Horizontal Pulse Grid
            </label>

            <label title="Subtle, pulsing glow emanating from the four corners, reacting to overall loudness." style="cursor: pointer;">
                <input type="checkbox" id="toggleFlash" data-effect="flash" style="transform: scale(1.1); margin-right: 8px;">
                Corner Flash (Pulsing Glow)
            </label>

            <label title="Time-domain audio waveform displayed vertically along the left and right edges (Oscilloscope effect)." style="cursor:pointer;">
                <input type="checkbox" id="toggleScope" data-effect="scope" style="transform: scale(1.1); margin-right: 8px;">
                Edge Oscilloscope (Waveform)
            </label>

            <label title="Rotates the entire video frame (plasma and all overlays) at 3 rotations per minute." style="cursor:pointer;">
                <input type="checkbox" id="toggleRotation" data-effect="rotation" style="transform: scale(1.1); margin-right: 8px;">
                Full Frame Rotation (3 RPM)
            </label>

            <label title="Modulates the depth (zoom) of the plasma vortex based on audio amplitude for a smooth, pulsing tunnel effect." style="cursor:pointer;">
                <input type="checkbox" id="toggleTunnel" data-effect="tunnel" style="transform: scale(1.1); margin-right: 8px;">
                Tunnel Depth Pulse
            </label>

            <label title="Floating text hints (e.g., 'HIGH ENERGY') that pulse and drift across the screen, reacting to the music." style="cursor:pointer;">
                <input type="checkbox" id="toggleMoodCloud" data-effect="moodcloud" style="transform: scale(1.1); margin-right: 8px;">
                Lyrical Mood Cloud
            </label>
        </div>
    </div>

    <div id="autoRecordControl">
        <input type="checkbox" id="autoRecord">
        <label for="autoRecord" style="font-size: 1.1rem;">Start recording automatically</label>
    </div>

    <div class="control-group">
        <h3>Audio Source</h3>
        <button id="startButton" class="button-style">
            Grant Microphone Access
        </button>
    </div>

    <div class="control-group">
        <h3>OR</h3>
        <input type="file" id="fileInput" accept="audio/*">
        <button id="loadFromFileButton" class="button-style">
            Load MP3 / Audio File
        </button>
    </div>

    <div id="message" class="error"></div>
</div>

<script>
    // --- Global Variables ---
    const canvas = document.getElementById('plasmaCanvas');
    const ctx = canvas.getContext('2d');
    const overlay = document.getElementById('overlay');
    const startButton = document.getElementById('startButton');
    const loadFromFileButton = document.getElementById('loadFromFileButton');
    const fileInput = document.getElementById('fileInput');
    const autoRecordCheckbox = document.getElementById('autoRecord');
    const messageDiv = document.getElementById('message');
    const fullscreenButton = document.getElementById('fullscreenButton');
    const recordContainer = document.getElementById('recordContainer');
    const recordButton = document.getElementById('recordButton');
    const recordingStatus = document.getElementById('recordingStatus');
    const stopVisualizerButton = document.getElementById('stopVisualizerButton');
    const effectCheckboxes = document.getElementById('effectCheckboxes');


    // OPTIMIZATION: Low-Resolution Off-Screen Canvas Setup
    const LOW_RES_WIDTH = 240;
    const LOW_RES_HEIGHT = 135;
    const tempCanvas = document.createElement('canvas');
    const tempCtx = tempCanvas.getContext('2d');
    tempCanvas.width = LOW_RES_WIDTH;
    tempCanvas.height = LOW_RES_HEIGHT;

    let audioContext;
    let analyser;
    let frequencyData;
    let timeData; // Array for time domain data
    let frameCount = 0;
    let isRunning = false;
    let mediaRecorder;
    let recordedChunks = [];
    let audioSourceNode;
    let mediaStream = null; // New: Reference to the live mic stream for cleanup

    // Global Aspect Ratio and View Variables
    const aspectRatio = 16 / 9;
    let viewWidth = 0;
    let viewHeight = 0;
    let offsetX = 0;
    let offsetY = 0;

    // Configuration for the plasma effect
    const config = {
        scale: 0.005,
        speed: 0.0005,
        rotation: 0.0000007,
        audioInfluence: 0.8,
        maxAmplitude: 0.0,
    };

    // State for visual effects toggles
    const activeEffects = {
        circles: true,
        analyzer: true,
        hgrid: false,
        flash: false,
        scope: false,
        rotation: false,
        tunnel: false,
        moodcloud: false,
    };

    // --- Local Storage Utilities ---
    const STORAGE_KEY = 'psychedelicVisualizerEffects';

    function saveEffects() {
        try {
            localStorage.setItem(STORAGE_KEY, JSON.stringify(activeEffects));
        } catch (e) {
            console.error("Error saving state to local storage", e);
        }
    }

    function loadEffects() {
        try {
            const savedState = localStorage.getItem(STORAGE_KEY);
            if (savedState) {
                return JSON.parse(savedState);
            }
        } catch (e) {
            console.error("Error loading state from local storage", e);
        }
        return null; // Return null if nothing is found or loading fails
    }

    // Load state immediately after defining defaults
    const loadedState = loadEffects();
    if (loadedState) {
        // Merge loaded state over defaults
        Object.assign(activeEffects, loadedState);
    }
    // --- End Local Storage Utilities ---


    // Rotation variables (3 rotations per minute = 1 rotation every 20 seconds)
    let globalRotation = 0;
    // 1 rotation / (60 FPS * 20 seconds) = 1/1200th of a revolution per frame
    var ROTATION_STEP = (2 * Math.PI) / 1200;

    // --- Mood Cloud State ---
    const moodWords = [
        "HIGH ENERGY", "DEEP BASS", "RHYTHM PUSH", "PEAK LOUDNESS",
        "MOMENTUM", "CHILL VIBE", "TRANSCEND", "ECHO LOOP", "COLOR SHIFT"
    ];
    const NUM_MOOD_ELEMENTS = 5;
    const moodElements = []; // Initialize here

    // Initialize Mood Elements (UPDATED with rotation properties)
    for (let i = 0; i < NUM_MOOD_ELEMENTS; i++) {
        moodElements.push({
            text: moodWords[i % moodWords.length],
            x: Math.random() * 0.8 + 0.1, // Normalized position (0.1 to 0.9)
            y: Math.random() * 0.8 + 0.1,
            vx: (Math.random() - 0.5) * 0.0005, // Normalized velocity
            vy: (Math.random() - 0.5) * 0.0005,
            opacity: 0.0,
            targetOpacity: 0.0,
            size: 20 + Math.random() * 10,
            rotation: Math.random() * 2 * Math.PI, // Initial random rotation
            rotationSpeed: (Math.random() - 0.5) * 0.005, // Slow rotation speed
        });
    }
    // --- End Mood Cloud State ---


    // --- Control Visibility Logic ---
    let controlsTimeout = null;
    const INACTIVITY_TIMEOUT = 10000; // 10 seconds

    /** Sets the visibility state of the overlay controls (Record button, Fullscreen button, Stop button). */
    function updateControlsVisibility(visible) {
        const opacityValue = visible ? '1' : '0';
        const eventsValue = visible ? 'auto' : 'none';

        // Apply to Record Container (includes both record and stop buttons)
        recordContainer.style.opacity = opacityValue;
        recordContainer.style.pointerEvents = eventsValue;

        // Apply to Fullscreen Button
        fullscreenButton.style.opacity = opacityValue;
        fullscreenButton.style.pointerEvents = eventsValue;
    }

    /** Shows controls and resets the hide timer. */
    function showControls() {
        if (!isRunning) return; // Only show controls after visualizer starts

        // Ensure the record container is display:flex so opacity works
        if (recordContainer.style.display !== 'flex') {
            recordContainer.style.display = 'flex';
        }

        updateControlsVisibility(true);

        clearTimeout(controlsTimeout);
        controlsTimeout = setTimeout(() => {
            updateControlsVisibility(false);
        }, INACTIVITY_TIMEOUT);
    }

    // Global mousemove listener to trigger controls visibility
    document.addEventListener('mousemove', showControls);
    // --- End Control Visibility Logic ---


    // --- Utility Functions ---

    /**
     * Numeric HSL to RGB conversion helper. Avoids string/regex ops.
     */
    const hue2rgb = (p, q, t) => {
        if (t < 0) t += 1;
        if (t > 1) t -= 1;
        if (t < 1 / 6) return p + (q - p) * 6 * t;
        if (t < 1 / 2) return q;
        if (t < 2 / 3) return p + (q - p) * (2 / 3 - t) * 6;
        return p;
    };


    /**
     * Toggles fullscreen mode for the entire document.
     */
    function toggleFullscreen() {
        if (!document.fullscreenElement) {
            document.documentElement.requestFullscreen().catch(err => {
                console.warn(`Error attempting to enable full-screen mode: ${err.message}`);
            });
        } else {
            if (document.exitFullscreen) {
                document.exitFullscreen();
            }
        }
    }

    /**
     * Common function to hide the overlay and start the animation loop.
     */
    function startVisualizer() {
        overlay.style.opacity = 0;
        setTimeout(() => { overlay.style.display = 'none'; }, 500);
        isRunning = true;
        animate();

        // Show controls initially and start the hide timer
        showControls();

        // Check if auto-recording is requested and start if checked
        if (autoRecordCheckbox.checked) {
            startRecording();
        }

        // Clear message once visualizer starts
        messageDiv.innerText = "";
    }

    /**
     * Resets the hidden file input element to allow a new file to be selected.
     */
    function resetFileInput() {
        // CRITICAL: Clear the file input value to allow the same file to be selected again
        fileInput.value = '';
    }

    /**
     * Stops all visual and audio playback and returns to the start screen.
     */
    function stopVisualizer() {
        isRunning = false;

        // Stop recording if active
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            stopRecording();
        }

        // --- CRITICAL CLEANUP: Stop and Disconnect Audio Source ---
        if (audioSourceNode) {
            try {
                // If it was a microphone stream, stop the tracks to release the device
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop());
                    mediaStream = null;
                }

                // Only call stop if it's a BufferSourceNode (file) or similar stream that needs it
                if (audioSourceNode.stop) audioSourceNode.stop();
                audioSourceNode.disconnect();
            } catch (e) {
                console.warn("Error stopping/disconnecting audio node during cleanup:", e);
            }
            audioSourceNode = null;
        }
        // --------------------------------------------------------

        resetFileInput(); // IMPORTANT: Reset file input on stop

        // Reset rotation angle
        globalRotation = 0;

        // Hide controls
        updateControlsVisibility(false);

        // Show overlay/start screen
        overlay.style.display = 'flex';
        setTimeout(() => { overlay.style.opacity = 1; }, 10); // Fade in

        // Reset message
        messageDiv.innerText = "";
    }


    // --- Audio Setup Functions ---

    /**
     * Initializes the Web Audio API for microphone access.
     */
    async function setupAudioFromMic() {
        try {
            // --- CLEANUP CHECK ---
            if (audioSourceNode) {
                try {
                    if (audioSourceNode.stop) audioSourceNode.stop();
                    audioSourceNode.disconnect();
                } catch (e) {
                    console.warn("Error cleaning up previous audio source:", e);
                }
                audioSourceNode = null;
            }
            // ---------------------

            resetFileInput(); // Reset file input when switching to mic

            // Ensure audio context is ready
            if (audioContext && audioContext.state === 'suspended') {
                await audioContext.resume();
            } else if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            analyser = audioContext.createAnalyser();
            analyser.fftSize = 512; /* Increased buffer size to 512 to help prevent pops/underruns */
            frequencyData = new Uint8Array(analyser.frequencyBinCount);
            timeData = new Uint8Array(analyser.fftSize); // Now uses the larger buffer

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaStream = stream; // Store the stream reference for explicit track cleanup
            audioSourceNode = audioContext.createMediaStreamSource(stream);

            // Connect: Source -> Analyser -> Destination (silently)
            audioSourceNode.connect(analyser);

            startVisualizer();
        } catch (err) {
            console.error("Microphone access failed:", err);
            messageDiv.innerText = "Error: Could not access microphone. Check permissions.";
        }
    }

    /**
     * Initializes the Web Audio API for local file access.
     */
    function setupAudioFromFile(file) {
        // --- CRITICAL CLEANUP: Stop and Disconnect Previous Source ---
        if (audioSourceNode) {
            try {
                if (audioSourceNode.stop) audioSourceNode.stop();
                audioSourceNode.disconnect();
            } catch (e) {
                console.warn("Error cleaning up previous audio source during file load:", e);
            }
            audioSourceNode = null;
        }

        mediaStream = null; // Ensure mic stream reference is cleared
        // ------------------------------------------------------------

        // Ensure audio context is ready
        if (audioContext && audioContext.state === 'suspended') {
            audioContext.resume();
        } else if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512; /* Increased buffer size to 512 to help prevent pops/underruns */
        frequencyData = new Uint8Array(analyser.frequencyBinCount);
        timeData = new Uint8Array(analyser.fftSize); // Now uses the larger buffer

        // INDICATION: Set loading message immediately upon file selection
        messageDiv.innerText = "Loading and decoding audio...";

        const reader = new FileReader();
        reader.onload = function(e) {
            audioContext.decodeAudioData(e.target.result, function(buffer) {
                audioSourceNode = audioContext.createBufferSource();
                audioSourceNode.buffer = buffer;

                // Connect: Source -> Analyser -> Destination (so we can hear it)
                // NOTE: Analyser is reused, so we only connect the new source node to it.
                audioSourceNode.connect(analyser);
                audioSourceNode.connect(audioContext.destination);

                // Set handler to stop recording when the file finishes
                audioSourceNode.onended = () => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        stopRecording();
                        messageDiv.innerText = "Audio finished and recording stopped automatically. Download is ready!";
                    } else if (isRunning) {
                        stopVisualizer(); // Return to start screen after file playback ends
                    }
                    resetFileInput(); // IMPORTANT: Reset file input when file ends
                };

                audioSourceNode.start(0);

                // Clear loading message and start visualizer
                startVisualizer();
            }, function(e) {
                messageDiv.innerText = `Error decoding audio data: ${e.err}`;
                resetFileInput(); // IMPORTANT: Reset file input on decode error
            });
        };
        reader.onerror = function(e) {
            messageDiv.innerText = `Error reading file: ${e.target.error}`;
            resetFileInput(); // IMPORTANT: Reset file input on read error
        };
        reader.readAsArrayBuffer(file);
    }

    // --- Event Listeners ---
    startButton.addEventListener('click', setupAudioFromMic);
    fullscreenButton.addEventListener('click', toggleFullscreen);
    stopVisualizerButton.addEventListener('click', stopVisualizer);

    loadFromFileButton.addEventListener('click', () => {
        fileInput.click(); // Trigger the hidden file input
    });

    fileInput.addEventListener('change', (e) => {
        const file = e.target.files[0];
        if (file) {
            // Do NOT call resetFileInput here, as it would immediately clear the file we need.
            setupAudioFromFile(file);
        }
    });

    // NEW: Checkbox listener to update active effects state
    effectCheckboxes.addEventListener('change', (e) => {
        if (e.target.type === 'checkbox') {
            const effectName = e.target.getAttribute('data-effect');
            if (effectName) {
                activeEffects[effectName] = e.target.checked;
                saveEffects(); // <-- PERSISTENT SAVE ON CHANGE
            }
        }
    });

    // --- Recording Logic ---

    /**
     * Starts capturing the canvas video stream and audio stream into a WebM file.
     */
    function startRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') return; // Prevent double recording

        try {
            // Get the video stream from the plasma canvas (60 FPS default)
            const videoStream = canvas.captureStream(60);

            // Get the audio stream from the Analyser Node (or the source, depending on what is available)
            const audioDest = audioContext.createMediaStreamDestination();
            // Ensure the analyser node is correctly connected to the stream destination for recording
            analyser.connect(audioDest);

            const audioStream = audioDest.stream;

            // Combine video and audio tracks
            const combinedStream = new MediaStream();
            videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
            audioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));

            // Create the Media Recorder instance
            mediaRecorder = new MediaRecorder(combinedStream, {
                mimeType: 'video/webm; codecs=vp8,opus'
            });

            mediaRecorder.ondataavailable = function(e) {
                if (e.data.size > 0) {
                    recordedChunks.push(e.data);
                }
            };

            mediaRecorder.onstop = function() {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);

                // Create a link to download the video
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;

                // Dynamically generate filename based on active effects
                const activeNames = Object.keys(activeEffects).filter(key => activeEffects[key]).join('-');
                const filename = activeNames.length > 0 ? activeNames : 'vortex';

                a.download = `plasma-${filename}-${Date.now()}.webm`;
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);

                // Reset state
                recordedChunks = [];
                recordButton.classList.remove('recording');
                recordingStatus.style.opacity = 0;
                recordButton.innerText = "START RECORDING (WebM)";

                // Disconnect analyser from audioDest to clean up recording chain
                analyser.disconnect(audioDest);
            };

            recordedChunks = [];
            mediaRecorder.start();
            recordButton.classList.add('recording');
            recordingStatus.style.opacity = 1;
            recordButton.innerText = "STOP RECORDING";

        } catch (error) {
            console.error("Recording setup failed:", error);
            messageDiv.innerText = "Error: Recording is not supported in this browser or context.";
        }
    }

    /**
     * Stops the recording process.
     */
    function stopRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
        }
    }

    recordButton.addEventListener('click', () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            stopRecording();
        } else {
            startRecording();
        }
    });


    // --- Visualization Logic ---

    /**
     * Updates audio analysis data (frequency and time domain) and overall amplitude.
     */
    function updateAudioAnalysis() {
        // Only update analysis if analyser is ready
        if (!analyser) return 0;

        // Get data
        analyser.getByteFrequencyData(frequencyData);
        analyser.getByteTimeDomainData(timeData); // Fetch time domain data

        // Calculate Amplitude (loudness)
        let sum = 0;
        for (const byte of frequencyData) {
            sum += byte;
        }
        const average = sum / frequencyData.length;
        const normalized = average / 255.0;

        // Smoothed value for visuals (0.7 decay,