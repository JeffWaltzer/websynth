<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio-Reactive Plasma Generator</title>
    <style>
        /* General Setup */
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background-color: #000;
            font-family: 'Inter', sans-serif;
            color: #fff;
        }

        /* Canvas Full Screen (Covers entire viewport) */
        #plasmaCanvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background-color: black;
            image-rendering: pixelated;
        }

        /* Overlay & Controls */
        #overlay {
            position: fixed;
            z-index: 100;
            padding: 30px;
            text-align: center;
            background: rgba(0, 0, 0, 0.85); /* Slightly darker overlay */
            border-radius: 12px;
            backdrop-filter: blur(5px);
            box-shadow: 0 0 40px rgba(255, 255, 255, 0.3);
            transition: opacity 0.5s;
        }

        #loadingText {
            font-size: 1.5rem;
            margin-bottom: 20px;
            color: #ffcc00;
        }

        #autoRecordControl {
            margin-bottom: 25px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #autoRecord {
            transform: scale(1.5);
            margin-right: 10px;
        }

        .control-group {
            margin-bottom: 20px;
            padding: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 8px;
        }

        .control-group h3 {
            margin-top: 0;
            color: #ccc;
        }

        .button-style {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 8px;
            transition: background-color 0.3s, transform 0.1s, box-shadow 0.3s;
            width: 90%;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.4);
        }

        .button-style:hover {
            background-color: #45a049;
            box-shadow: 0 6px 20px rgba(76, 175, 80, 0.5);
        }

        .button-style:active {
            transform: scale(0.98);
        }

        #fileInput {
            display: none;
        }

        #loadFromFileButton {
            background-color: #008CBA; /* Blue for file load */
        }
        #loadFromFileButton:hover {
            background-color: #007bb5;
            box-shadow: 0 6px 20px rgba(0, 140, 186, 0.5);
        }

        .error {
            color: #ff4d4d;
            font-weight: bold;
            margin-top: 10px;
        }

        /* Message box styling for clarity */
        #message {
            text-align: left;
            padding: 15px;
            background-color: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
        }

        /* Fullscreen Button Style */
        #fullscreenButton {
            position: fixed;
            bottom: 20px;
            right: 20px;
            z-index: 60;
            background-color: rgba(30, 30, 30, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            width: 44px;
            height: 44px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease-in-out, background-color 0.2s, box-shadow 0.2s;
        }

        #fullscreenButton:hover {
            background-color: rgba(50, 50, 50, 0.9);
            box-shadow: 0 0 10px rgba(255, 255, 255, 0.5);
        }

        #fullscreenButton svg {
            fill: white;
            width: 24px;
            height: 24px;
        }

        /* Record Button Style */
        #recordContainer {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 60;
            display: none;
            flex-direction: column;
            align-items: center;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease-in-out;
        }

        #recordButton {
            background-color: #f44336; /* Red */
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: bold;
            cursor: pointer;
            border: none;
            transition: background-color 0.3s, opacity 0.3s;
        }

        #recordButton.recording {
            background-color: #ff0000;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 0, 0, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 0, 0, 0); }
        }

        #recordingStatus {
            margin-top: 5px;
            color: #f44336;
            font-size: 0.9rem;
            font-weight: bold;
            opacity: 0;
            transition: opacity 0.3s;
        }
        /* Stop Visualizer Button Specific Style */
        #stopVisualizerButton {
            background-color: #6c757d;
            margin-top: 10px;
            width: 100%;
            padding: 10px 20px;
            font-size: 1rem;
        }
        #stopVisualizerButton:hover {
            background-color: #5a6268;
            box-shadow: 0 6px 20px rgba(108, 117, 125, 0.5);
        }
    </style>
</head>
<body>

<canvas id="plasmaCanvas"></canvas>


<button id="fullscreenButton" title="Toggle Fullscreen">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <path d="M7 14H5v5h5v-2H7v-3zm-2-4h2V7h3V5H5v5zm12 7h-3v2h5v-5h-2v3zM14 5v2h3v3h2V5h-5z"/>
    </svg>
</button>

<div id="recordContainer">
    <button id="recordButton">START RECORDING (WebM)</button>
    <div id="recordingStatus">Recording...</div>
    <button id="stopVisualizerButton" class="button-style">STOP VISUALIZER</button>
</div>


<div id="overlay">
    <div id="loadingText">
        Choose your audio source and visual effect to start.
    </div>

    <div class="control-group">
        <h3>Overlay Effects (Select one or more)</h3>
        <div id="effectCheckboxes" style="text-align: left; display: flex; flex-direction: column; gap: 10px; padding: 5px;">

            <label title="Concentric circles that deform and ripple like an oscilloscope based on mid-high frequencies." style="cursor: pointer;">
                <input type="checkbox" id="toggleCircles" data-effect="circles" checked style="transform: scale(1.1); margin-right: 8px;">
                Concentric Circles (Radial Waves)
            </label>

            <label title="A central, spinning ring of bars representing the full audio spectrum." style="cursor: pointer;">
                <input type="checkbox" id="toggleAnalyzer" data-effect="analyzer" checked style="transform: scale(1.1); margin-right: 8px;">
                Radial Analyzer (Spectrograph)
            </label>

            <label title="Bass-driven grid of vertical bars on the top and bottom edges that pulse with the rhythm." style="cursor: pointer;">
                <input type="checkbox" id="toggleHgrid" data-effect="hgrid" style="transform: scale(1.1); margin-right: 8px;">
                Horizontal Pulse Grid
            </label>

            <label title="Subtle, pulsing glow emanating from the four corners, reacting to overall loudness." style="cursor: pointer;">
                <input type="checkbox" id="toggleFlash" data-effect="flash" style="transform: scale(1.1); margin-right: 8px;">
                Corner Flash (Pulsing Glow)
            </label>

            <label title="Time-domain audio waveform displayed vertically along the left and right edges (Oscilloscope effect)." style="cursor:pointer;">
                <input type="checkbox" id="toggleScope" data-effect="scope" style="transform: scale(1.1); margin-right: 8px;">
                Edge Oscilloscope (Waveform)
            </label>

            <label title="Rotates the entire video frame (plasma and all overlays) at 3 rotations per minute." style="cursor:pointer;">
                <input type="checkbox" id="toggleRotation" data-effect="rotation" style="transform: scale(1.1); margin-right: 8px;">
                Full Frame Rotation (3 RPM)
            </label>

            <label title="Modulates the depth (zoom) of the plasma vortex based on audio amplitude for a smooth, pulsing tunnel effect." style="cursor:pointer;">
                <input type="checkbox" id="toggleTunnel" data-effect="tunnel" style="transform: scale(1.1); margin-right: 8px;">
                Tunnel Depth Pulse
            </label>

            <label title="Floating text hints (e.g., 'HIGH ENERGY') that pulse and drift across the screen, reacting to the music." style="cursor:pointer;">
                <input type="checkbox" id="toggleMoodCloud" data-effect="moodcloud" style="transform: scale(1.1); margin-right: 8px;">
                Lyrical Mood Cloud
            </label>
        </div>
    </div>

    <div id="autoRecordControl">
        <input type="checkbox" id="autoRecord">
        <label for="autoRecord" style="font-size: 1.1rem;">Start recording automatically</label>
    </div>

    <div class="control-group">
        <h3>Audio Source</h3>
        <button id="startButton" class="button-style">
            Grant Microphone Access
        </button>
    </div>

    <div class="control-group">
        <h3>OR</h3>
        <input type="file" id="fileInput" accept="audio/*">
        <button id="loadFromFileButton" class="button-style">
            Load MP3 / Audio File
        </button>
    </div>

    <div id="message" class="error"></div>
</div>

<script>
    // --- Global Variables ---
    const canvas = document.getElementById('plasmaCanvas');
    const ctx = canvas.getContext('2d');
    const overlay = document.getElementById('overlay');
    const startButton = document.getElementById('startButton');
    const loadFromFileButton = document.getElementById('loadFromFileButton');
    const fileInput = document.getElementById('fileInput');
    const autoRecordCheckbox = document.getElementById('autoRecord');
    const messageDiv = document.getElementById('message');
    const fullscreenButton = document.getElementById('fullscreenButton');
    const recordContainer = document.getElementById('recordContainer');
    const recordButton = document.getElementById('recordButton');
    const recordingStatus = document.getElementById('recordingStatus');
    const stopVisualizerButton = document.getElementById('stopVisualizerButton');
    const effectCheckboxes = document.getElementById('effectCheckboxes');


    // OPTIMIZATION: Low-Resolution Off-Screen Canvas Setup
    const LOW_RES_WIDTH = 240;
    const LOW_RES_HEIGHT = 135;
    const tempCanvas = document.createElement('canvas');
    const tempCtx = tempCanvas.getContext('2d');
    tempCanvas.width = LOW_RES_WIDTH;
    tempCanvas.height = LOW_RES_HEIGHT;

    let audioContext;
    let analyser;
    let frequencyData;
    let timeData; // Array for time domain data
    let frameCount = 0;
    let isRunning = false;
    let mediaRecorder;
    let recordedChunks = [];
    let audioSourceNode;
    let mediaStream = null; // New: Reference to the live mic stream for cleanup

    // Global Aspect Ratio and View Variables
    const aspectRatio = 16 / 9;
    let viewWidth = 0;
    let viewHeight = 0;
    let offsetX = 0;
    let offsetY = 0;

    // Configuration for the plasma effect
    const config = {
        scale: 0.005,
        speed: 0.0005,
        rotation: 0.0000007,
        audioInfluence: 0.8,
        maxAmplitude: 0.0,
    };

    // State for visual effects toggles
    const activeEffects = {
        circles: true,
        analyzer: true,
        hgrid: false,
        flash: false,
        scope: false,
        rotation: false,
        tunnel: false,
        moodcloud: false,
    };

    // --- Local Storage Utilities ---
    const STORAGE_KEY = 'psychedelicVisualizerEffects';

    function saveEffects() {
        try {
            localStorage.setItem(STORAGE_KEY, JSON.stringify(activeEffects));
        } catch (e) {
            console.error("Error saving state to local storage", e);
        }
    }

    function loadEffects() {
        try {
            const savedState = localStorage.getItem(STORAGE_KEY);
            if (savedState) {
                return JSON.parse(savedState);
            }
        } catch (e) {
            console.error("Error loading state from local storage", e);
        }
        return null; // Return null if nothing is found or loading fails
    }

    // Load state immediately after defining defaults
    const loadedState = loadEffects();
    if (loadedState) {
        // Merge loaded state over defaults
        Object.assign(activeEffects, loadedState);
    }
    // --- End Local Storage Utilities ---


    // Rotation variables (3 rotations per minute = 1 rotation every 20 seconds)
    let globalRotation = 0;
    // 1 rotation / (60 FPS * 20 seconds) = 1/1200th of a revolution per frame
    var ROTATION_STEP = (2 * Math.PI) / 1200;

    // --- Mood Cloud State ---
    const moodWords = [
        "HIGH ENERGY", "DEEP BASS", "RHYTHM PUSH", "PEAK LOUDNESS",
        "MOMENTUM", "CHILL VIBE", "TRANSCEND", "ECHO LOOP", "COLOR SHIFT"
    ];
    const NUM_MOOD_ELEMENTS = 5;
    const moodElements = []; // Initialize here

    // Initialize Mood Elements (UPDATED with rotation properties)
    for (let i = 0; i < NUM_MOOD_ELEMENTS; i++) {
        moodElements.push({
            text: moodWords[i % moodWords.length],
            x: Math.random() * 0.8 + 0.1, // Normalized position (0.1 to 0.9)
            y: Math.random() * 0.8 + 0.1,
            vx: (Math.random() - 0.5) * 0.0005, // Normalized velocity
            vy: (Math.random() - 0.5) * 0.0005,
            opacity: 0.0,
            targetOpacity: 0.0,
            size: 20 + Math.random() * 10,
            rotation: Math.random() * 2 * Math.PI, // Initial random rotation
            rotationSpeed: (Math.random() - 0.5) * 0.005, // Slow rotation speed
        });
    }
    // --- End Mood Cloud State ---


    // --- Control Visibility Logic ---
    let controlsTimeout = null;
    const INACTIVITY_TIMEOUT = 10000; // 10 seconds

    /** Sets the visibility state of the overlay controls (Record button, Fullscreen button, Stop button). */
    function updateControlsVisibility(visible) {
        const opacityValue = visible ? '1' : '0';
        const eventsValue = visible ? 'auto' : 'none';

        // Apply to Record Container (includes both record and stop buttons)
        recordContainer.style.opacity = opacityValue;
        recordContainer.style.pointerEvents = eventsValue;

        // Apply to Fullscreen Button
        fullscreenButton.style.opacity = opacityValue;
        fullscreenButton.style.pointerEvents = eventsValue;
    }

    /** Shows controls and resets the hide timer. */
    function showControls() {
        if (!isRunning) return; // Only show controls after visualizer starts

        // Ensure the record container is display:flex so opacity works
        if (recordContainer.style.display !== 'flex') {
            recordContainer.style.display = 'flex';
        }

        updateControlsVisibility(true);

        clearTimeout(controlsTimeout);
        controlsTimeout = setTimeout(() => {
            updateControlsVisibility(false);
        }, INACTIVITY_TIMEOUT);
    }

    // Global mousemove listener to trigger controls visibility
    document.addEventListener('mousemove', showControls);
    // --- End Control Visibility Logic ---


    // --- Utility Functions ---

    /**
     * Numeric HSL to RGB conversion helper. Avoids string/regex ops.
     */
    const hue2rgb = (p, q, t) => {
        if (t < 0) t += 1;
        if (t > 1) t -= 1;
        if (t < 1 / 6) return p + (q - p) * 6 * t;
        if (t < 1 / 2) return q;
        if (t < 2 / 3) return p + (q - p) * (2 / 3 - t) * 6;
        return p;
    };


    /**
     * Toggles fullscreen mode for the entire document.
     */
    function toggleFullscreen() {
        if (!document.fullscreenElement) {
            document.documentElement.requestFullscreen().catch(err => {
                console.warn(`Error attempting to enable full-screen mode: ${err.message}`);
            });
        } else {
            if (document.exitFullscreen) {
                document.exitFullscreen();
            }
        }
    }

    /**
     * Common function to hide the overlay and start the animation loop.
     */
    function startVisualizer() {
        overlay.style.opacity = 0;
        setTimeout(() => { overlay.style.display = 'none'; }, 500);
        isRunning = true;
        animate();

        // Show controls initially and start the hide timer
        showControls();

        // Check if auto-recording is requested and start if checked
        if (autoRecordCheckbox.checked) {
            startRecording();
        }

        // Clear message once visualizer starts
        messageDiv.innerText = "";
    }

    /**
     * Resets the hidden file input element to allow a new file to be selected.
     */
    function resetFileInput() {
        // CRITICAL: Clear the file input value to allow the same file to be selected again
        fileInput.value = '';
    }

    /**
     * Stops all visual and audio playback and returns to the start screen.
     */
    function stopVisualizer() {
        isRunning = false;

        // Stop recording if active
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            stopRecording();
        }

        // --- CRITICAL CLEANUP: Stop and Disconnect Audio Source ---
        if (audioSourceNode) {
            try {
                // If it was a microphone stream, stop the tracks to release the device
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop());
                    mediaStream = null;
                }

                // Only call stop if it's a BufferSourceNode (file) or similar stream that needs it
                if (audioSourceNode.stop) audioSourceNode.stop();
                audioSourceNode.disconnect();
            } catch (e) {
                console.warn("Error stopping/disconnecting audio node during cleanup:", e);
            }
            audioSourceNode = null;
        }
        // --------------------------------------------------------

        resetFileInput(); // IMPORTANT: Reset file input on stop

        // Reset rotation angle
        globalRotation = 0;

        // Hide controls
        updateControlsVisibility(false);

        // Show overlay/start screen
        overlay.style.display = 'flex';
        setTimeout(() => { overlay.style.opacity = 1; }, 10); // Fade in

        // Reset message
        messageDiv.innerText = "";
    }


    // --- Audio Setup Functions ---

    /**
     * Initializes the Web Audio API for microphone access.
     */
    async function setupAudioFromMic() {
        try {
            // --- CLEANUP CHECK ---
            if (audioSourceNode) {
                try {
                    if (audioSourceNode.stop) audioSourceNode.stop();
                    audioSourceNode.disconnect();
                } catch (e) {
                    console.warn("Error cleaning up previous audio source:", e);
                }
                audioSourceNode = null;
            }
            // ---------------------

            resetFileInput(); // Reset file input when switching to mic

            // Ensure audio context is ready
            if (audioContext && audioContext.state === 'suspended') {
                await audioContext.resume();
            } else if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            analyser = audioContext.createAnalyser();
            analyser.fftSize = 512; /* Increased buffer size to 512 to help prevent pops/underruns */
            frequencyData = new Uint8Array(analyser.frequencyBinCount);
            timeData = new Uint8Array(analyser.fftSize); // Now uses the larger buffer

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaStream = stream; // Store the stream reference for explicit track cleanup
            audioSourceNode = audioContext.createMediaStreamSource(stream);

            // Connect: Source -> Analyser -> Destination (silently)
            audioSourceNode.connect(analyser);

            startVisualizer();
        } catch (err) {
            console.error("Microphone access failed:", err);
            messageDiv.innerText = "Error: Could not access microphone. Check permissions.";
        }
    }

    /**
     * Initializes the Web Audio API for local file access.
     */
    function setupAudioFromFile(file) {
        // --- CRITICAL CLEANUP: Stop and Disconnect Previous Source ---
        if (audioSourceNode) {
            try {
                if (audioSourceNode.stop) audioSourceNode.stop();
                audioSourceNode.disconnect();
            } catch (e) {
                console.warn("Error cleaning up previous audio source during file load:", e);
            }
            audioSourceNode = null;
        }

        mediaStream = null; // Ensure mic stream reference is cleared
        // ------------------------------------------------------------

        // Ensure audio context is ready
        if (audioContext && audioContext.state === 'suspended') {
            audioContext.resume();
        } else if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512; /* Increased buffer size to 512 to help prevent pops/underruns */
        frequencyData = new Uint8Array(analyser.frequencyBinCount);
        timeData = new Uint8Array(analyser.fftSize); // Now uses the larger buffer

        // INDICATION: Set loading message immediately upon file selection
        messageDiv.innerText = "Loading and decoding audio...";

        const reader = new FileReader();
        reader.onload = function(e) {
            audioContext.decodeAudioData(e.target.result, function(buffer) {
                audioSourceNode = audioContext.createBufferSource();
                audioSourceNode.buffer = buffer;

                // Connect: Source -> Analyser -> Destination (so we can hear it)
                // NOTE: Analyser is reused, so we only connect the new source node to it.
                audioSourceNode.connect(analyser);
                audioSourceNode.connect(audioContext.destination);

                // Set handler to stop recording when the file finishes
                audioSourceNode.onended = () => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        stopRecording();
                        messageDiv.innerText = "Audio finished and recording stopped automatically. Download is ready!";
                    } else if (isRunning) {
                        stopVisualizer(); // Return to start screen after file playback ends
                    }
                    resetFileInput(); // IMPORTANT: Reset file input when file ends
                };

                audioSourceNode.start(0);

                // Clear loading message and start visualizer
                startVisualizer();
            }, function(e) {
                messageDiv.innerText = `Error decoding audio data: ${e.err}`;
                resetFileInput(); // IMPORTANT: Reset file input on decode error
            });
        };
        reader.onerror = function(e) {
            messageDiv.innerText = `Error reading file: ${e.target.error}`;
            resetFileInput(); // IMPORTANT: Reset file input on read error
        };
        reader.readAsArrayBuffer(file);
    }

    // --- Event Listeners ---
    startButton.addEventListener('click', setupAudioFromMic);
    fullscreenButton.addEventListener('click', toggleFullscreen);
    stopVisualizerButton.addEventListener('click', stopVisualizer);

    loadFromFileButton.addEventListener('click', () => {
        fileInput.click(); // Trigger the hidden file input
    });

    fileInput.addEventListener('change', (e) => {
        const file = e.target.files[0];
        if (file) {
            // Do NOT call resetFileInput here, as it would immediately clear the file we need.
            setupAudioFromFile(file);
        }
    });

    // NEW: Checkbox listener to update active effects state
    effectCheckboxes.addEventListener('change', (e) => {
        if (e.target.type === 'checkbox') {
            const effectName = e.target.getAttribute('data-effect');
            if (effectName) {
                activeEffects[effectName] = e.target.checked;
                saveEffects(); // <-- PERSISTENT SAVE ON CHANGE
            }
        }
    });

    // --- Recording Logic ---

    /**
     * Starts capturing the canvas video stream and audio stream into a WebM file.
     */
    function startRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') return; // Prevent double recording

        try {
            // Get the video stream from the plasma canvas (60 FPS default)
            const videoStream = canvas.captureStream(60);

            // Get the audio stream from the Analyser Node (or the source, depending on what is available)
            const audioDest = audioContext.createMediaStreamDestination();
            // Ensure the analyser node is correctly connected to the stream destination for recording
            analyser.connect(audioDest);

            const audioStream = audioDest.stream;

            // Combine video and audio tracks
            const combinedStream = new MediaStream();
            videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
            audioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));

            // Create the Media Recorder instance
            mediaRecorder = new MediaRecorder(combinedStream, {
                mimeType: 'video/webm; codecs=vp8,opus'
            });

            mediaRecorder.ondataavailable = function(e) {
                if (e.data.size > 0) {
                    recordedChunks.push(e.data);
                }
            };

            mediaRecorder.onstop = function() {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);

                // Create a link to download the video
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;

                // Dynamically generate filename based on active effects
                const activeNames = Object.keys(activeEffects).filter(key => activeEffects[key]).join('-');
                const filename = activeNames.length > 0 ? activeNames : 'vortex';

                a.download = `plasma-${filename}-${Date.now()}.webm`;
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);

                // Reset state
                recordedChunks = [];
                recordButton.classList.remove('recording');
                recordingStatus.style.opacity = 0;
                recordButton.innerText = "START RECORDING (WebM)";

                // Disconnect analyser from audioDest to clean up recording chain
                analyser.disconnect(audioDest);
            };

            recordedChunks = [];
            mediaRecorder.start();
            recordButton.classList.add('recording');
            recordingStatus.style.opacity = 1;
            recordButton.innerText = "STOP RECORDING";

        } catch (error) {
            console.error("Recording setup failed:", error);
            messageDiv.innerText = "Error: Recording is not supported in this browser or context.";
        }
    }

    /**
     * Stops the recording process.
     */
    function stopRecording() {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
        }
    }

    recordButton.addEventListener('click', () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            stopRecording();
        } else {
            startRecording();
        }
    });


    // --- Visualization Logic ---

    /**
     * Updates audio analysis data (frequency and time domain) and overall amplitude.
     */
    function updateAudioAnalysis() {
        // Only update analysis if analyser is ready
        if (!analyser) return 0;

        // Get data
        analyser.getByteFrequencyData(frequencyData);
        analyser.getByteTimeDomainData(timeData); // Fetch time domain data

        // Calculate Amplitude (loudness)
        let sum = 0;
        for (const byte of frequencyData) {
            sum += byte;
        }
        const average = sum / frequencyData.length;
        const normalized = average / 255.0;

        // Smoothed value for visuals (0.7 decay, 0.3 new value for rapid response)
        config.maxAmplitude = config.maxAmplitude * 0.7 + normalized * 0.3;

        return config.maxAmplitude;
    }


    /**
     * Generates the plasma effect on the low-resolution tempCanvas.
     */
    function drawPlasma() {
        const width = LOW_RES_WIDTH;
        const height = LOW_RES_HEIGHT;
        const t = frameCount * config.speed;
        const audioAmp = config.maxAmplitude; // Use smoothed amplitude

        // Adjust parameters based on audio (HIGH INFLUENCE)
        const colorShift = audioAmp * 400 + t * 800;
        const rotationFactor = config.rotation + audioAmp * 0.000005;
        const dynamicScale = config.scale + audioAmp * 0.01;

        const imageData = tempCtx.getImageData(0, 0, width, height);
        const data = imageData.data;

        const cx = width / 2;
        const cy = height / 2;

        for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
                const i = (y * width + x) * 4;

                // Original Plasma Layer
                const rx = (x - cx) * rotationFactor;
                const ry = (y - cy) * rotationFactor;
                const r = Math.sqrt(rx * rx + ry * ry) * dynamicScale;
                const angle = Math.atan2(ry, rx);

                let v1 = 0;
                v1 += Math.sin((x * dynamicScale) + t);
                v1 += Math.sin((y * dynamicScale) + t * 0.5);
                v1 += Math.sin((x * dynamicScale + y * dynamicScale) + t * 0.25);
                v1 += Math.sin((r * 25 + angle * 2.5) * (1 + audioAmp * 1.5) + t * 0.8);

                // Second Noise Layer (more fractal/turbulent)
                const x2 = x - width / 2;
                const y2 = y - height / 2;
                let v2 = 0;
                v2 += Math.sin(x2 * 0.03 + t * 1.2 + y2 * 0.01);
                v2 += Math.sin(y2 * 0.02 + t * 0.9 - x2 * 0.01);
                v2 += Math.sin(Math.sqrt(x2 * x2 + y2 * y2) * 0.01 + t * 0.5);
                v2 = v2 * (1 + audioAmp * 2.0); // Amplify this layer with audio

                // Blend the two layers, audio influence decides blend strength
                const blendFactor = 0.5 + audioAmp * 0.8;
                let v = v1 * (1 - blendFactor) + v2 * blendFactor;


                // --- Highly Optimized HSL to RGB Conversion (Numeric Only) ---
                const h = ((v * 30 + colorShift) % 360) / 360; // Normalize hue to [0, 1]
                const s = 1.0;
                const l = 0.5 + audioAmp * 0.3; // Lightness [0.5, 0.8]

                let r_norm, g_norm, b_norm;

                if (s === 0) {
                    r_norm = g_norm = b_norm = l; // Achromatic
                } else {
                    const q = l < 0.5 ? l * (1 + s) : l + s - l * s;
                    const p = 2 * l - q;
                    r_norm = hue2rgb(p, q, h + 1 / 3);
                    g_norm = hue2rgb(p, q, h);
                    b_norm = hue2rgb(p, q, h - 1 / 3);
                }

                // Write RGB integers (0-255) to the data array
                data[i] = Math.round(r_norm * 255);
                data[i + 1] = Math.round(g_norm * 255);
                data[i + 2] = Math.round(b_norm * 255);
                data[i + 3] = 255;
            }
        }

        tempCtx.putImageData(imageData, 0, 0);
    }


    /**
     * Draws full-screen, audio-reactive circular waves with oscilloscope ripples.
     */
    function drawCircularWaves() {
        if (!analyser) return;

        const width = viewWidth;
        const height = viewHeight;
        const t = frameCount * 0.03;

        // OPTIMIZATION: Move context setup outside the loop.
        const centerX = width / 2;
        const centerY = height / 2;

        ctx.save();
        ctx.translate(offsetX, offsetY);

        ctx.globalAlpha = 0.7;
        ctx.lineWidth = 4;
        ctx.shadowBlur = 15;

        const numCircles = 8;
        const maxRadius = Math.min(width, height) / 2;
        const radiusStep = maxRadius / (numCircles + 1);

        const numSegments = 64;
        const angleIncrement = (2 * Math.PI) / numSegments;

        const ampScale = 0.05;
        const rippleMaxOffset = 30;

        for (let i = 0; i < numCircles; i++) {
            const baseFreqIndex = Math.floor((i + 1) * (frequencyData.length / (numCircles * 2)) + 10);
            const frequencyValue = frequencyData[baseFreqIndex] / 255.0;

            const baseRadius = (i + 1) * radiusStep;
            const rippleAmplitude = frequencyValue * 30 * (1 + config.maxAmplitude * 0.5);
            const overallRadius = baseRadius + rippleAmplitude * Math.sin(t * 2 + i * 0.5);

            const hue = (i * 45 + frameCount * 0.5) % 360;
            ctx.strokeStyle = `hsl(${hue}, 100%, 80%)`;
            ctx.shadowColor = `hsl(${hue}, 100%, 60%)`;

            ctx.beginPath();

            // Draw the custom polygonal circle with ripples
            for (let k = 0; k <= numSegments; k++) {
                const angle = k * angleIncrement;

                const rippleFreqIndex = (baseFreqIndex + Math.floor(k * ampScale * frequencyData.length)) % frequencyData.length;

                const normalizedRipple = frequencyData[rippleFreqIndex] / 255.0;
                const rippleDisplacement = normalizedRipple * rippleMaxOffset * (1 + config.maxAmplitude * 0.2);

                const finalRadius = overallRadius + rippleDisplacement;

                const x = centerX + finalRadius * Math.cos(angle);
                const y = centerY + finalRadius * Math.sin(angle);

                if (k === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }
            }
            ctx.closePath();
            ctx.stroke();
        }

        ctx.restore();
    }

    /**
     * Draws a circular, trippy spectrograph on the main canvas.
     */
    function drawSpectrograph() {
        if (!analyser) return;

        const centerX = viewWidth / 2 + offsetX;
        const centerY = viewHeight / 2 + offsetY;
        const radius = Math.min(viewWidth / 2, viewHeight / 2) * 0.3;
        const barWidth = 6;
        const barSpacing = 1;
        const maxBarHeight = Math.min(viewWidth / 2, viewHeight / 2) * 0.5;

        const numBars = 64;
        const freqStep = Math.floor(frequencyData.length / numBars);
        const angleStep = (2 * Math.PI) / numBars;

        ctx.save();
        ctx.translate(centerX, centerY);

        ctx.globalAlpha = 0.9;
        ctx.shadowBlur = 12;

        for (let j = 0; j < numBars; j++) {
            let amp = frequencyData[j * freqStep];
            let normalizedAmp = amp / 255;

            const barHeight = normalizedAmp * maxBarHeight * (1 + config.maxAmplitude * 0.5);

            const hue = (j * (360 / numBars) + frameCount * 1.5) % 360;

            // OPTIMIZATION: Combine save/restore outside the loop, use transforms.
            ctx.rotate(angleStep); // Rotate the whole canvas

            ctx.fillStyle = `hsl(${hue}, 100%, 70%)`;
            ctx.shadowColor = `hsl(${hue}, 100%, 50%)`;

            ctx.fillRect(
                radius,
                -barWidth / 2,
                barHeight,
                barWidth - barSpacing
            );
        }

        // We rotate back by the total rotation amount to keep the canvas aligned for the next frame
        ctx.rotate(-(angleStep * numBars));

        ctx.restore();
        ctx.shadowBlur = 0;
        ctx.shadowColor = 'transparent';
    }


    /**
     * Draws the audio waveform along the left and right edges (Oscilloscope effect).
     */
    function drawOscilloscope() {
        if (!analyser) return;

        const width = viewWidth;
        const height = viewHeight;
        const bufferLength = timeData.length;
        const sliceHeight = height * 1.0 / bufferLength; // Vertical step size

        // Dynamic Scaling based on overall sound amplitude
        const amp = config.maxAmplitude;
        const dynamicScale = 1.0 + amp * 2.5; // Scale from 1x to 3.5x for more energy

        const sideX = 30; // Base X position from the edge for offset
        const amplitudeScale = 67.5 * dynamicScale; // Base amplitude for width

        ctx.save();
        ctx.translate(offsetX, offsetY);

        ctx.globalAlpha = 1.0;
        ctx.lineWidth = 3;
        ctx.shadowBlur = 12;
        ctx.lineJoin = 'round';

        const hue = (frameCount * 2) % 360;
        ctx.strokeStyle = `hsl(${hue}, 100%, 75%)`;
        ctx.shadowColor = ctx.strokeStyle;

        // --- Draw Left Waveform ---
        ctx.beginPath();
        let y = 0;

        for (let i = 0; i < bufferLength; i++) {
            const v = (timeData[i] - 128) / 128; // Normalize to [-1, 1]

            // X position is offset from the left edge (sideX) based on amplitude
            const x = sideX + v * amplitudeScale;

            if (i === 0) {
                ctx.moveTo(x, y);
            } else {
                ctx.lineTo(x, y);
            }
            y += sliceHeight;
        }
        ctx.stroke();

        // --- Draw Right Waveform ---
        ctx.beginPath();
        y = 0;

        for (let i = 0; i < bufferLength; i++) {
            const v = (timeData[i] - 128) / 128;

            // X position is offset INWARD from the right edge (width - sideX) based on amplitude
            const x = width - sideX + v * amplitudeScale;

            if (i === 0) {
                ctx.moveTo(x, y);
            } else {
                ctx.lineTo(x, y);
            }
            y += sliceHeight;
        }
        ctx.stroke();

        ctx.restore();
        ctx.shadowBlur = 0;
    }

    /**
     * Draws a pulsing corner flash/vignette based on overall amplitude. (Option 1)
     */
    function drawCornerFlash() {
        if (!analyser) return;

        const width = viewWidth;
        const height = viewHeight;
        const amp = config.maxAmplitude;

        // Fade the opacity slightly behind the audio cue
        const pulseOpacity = amp * 0.6;
        const radius = Math.min(width, height) * 0.6; // Large radius

        ctx.save();
        ctx.translate(offsetX, offsetY);
        ctx.globalAlpha = pulseOpacity;
        ctx.shadowBlur = 20;

        const corners = [
            { x: 0, y: 0, color: '20, 255, 255' }, // Top-Left (Cyan)
            { x: width, y: 0, color: '255, 255, 20' }, // Top-Right (Yellow)
            { x: width, y: height, color: '255, 20, 255' }, // Bottom-Right (Magenta)
            { x: 0, y: height, color: '20, 255, 20' } // Bottom-Left (Green)
        ];

        for (const corner of corners) {
            const gradient = ctx.createRadialGradient(corner.x, corner.y, 0, corner.x, corner.y, radius);

            // Pulsing color based on base color and current amplitude
            const innerAlpha = Math.min(1, amp * 1.5);

            gradient.addColorStop(0, `rgba(${corner.color}, ${innerAlpha})`);
            gradient.addColorStop(0.3, `rgba(${corner.color}, ${pulseOpacity * 0.5})`);
            gradient.addColorStop(1, 'rgba(0, 0, 0, 0)');

            ctx.fillStyle = gradient;
            ctx.shadowColor = `rgba(${corner.color}, 0.8)`;
            ctx.fillRect(0, 0, width, height);
        }

        ctx.restore();
        ctx.shadowBlur = 0;
    }

    /**
     * Draws horizontal vertical bars that pulse with the bass (Grid effect).
     */
    function drawHorizontalPulseGrid() {
        if (!analyser) return;

        const width = viewWidth;
        const height = viewHeight;
        const t = frameCount * 0.05;

        // Target the low frequencies (first 10 bins) for a bass-driven pulse
        let bassSum = 0;
        const BASS_BINS = 10;
        for(let i = 0; i < BASS_BINS; i++) {
            bassSum += frequencyData[i];
        }
        // Further reduced amplification for bass sensitivity
        const normalizedBass = (bassSum / (BASS_BINS * 255.0)) * 0.2;

        const numBars = 100; // Density
        const barSpacing = width / numBars;
        // Further reduced max height
        const maxBarHeight = 5 * (0.5 + normalizedBass * 0.5); // Reduced max height to 5, scaled by bass
        const hue = (frameCount * 1.0) % 360;

        ctx.save();
        ctx.translate(offsetX, offsetY);

        ctx.globalAlpha = 0.4; // Slightly more translucent
        ctx.lineWidth = 1; // Thinner lines
        ctx.shadowBlur = 3; // Softer shadow
        ctx.strokeStyle = `hsl(${hue}, 100%, 70%)`;
        ctx.shadowColor = `hsl(${hue}, 100%, 50%)`;

        // --- Draw Top Edge Grid ---
        for (let i = 0; i < numBars; i++) {
            const x = i * barSpacing;
            // Introduce small random variation and sine movement
            const wave = Math.sin(x * 0.05 + t) * 0.5;
            const barHeight = maxBarHeight * (0.5 + wave * 0.5); // Adjusted calculation

            ctx.beginPath();
            ctx.moveTo(x, 0);
            ctx.lineTo(x, barHeight);
            ctx.stroke();
        }

        // --- Draw Bottom Edge Grid ---
        for (let i = 0; i < numBars; i++) {
            const x = i * barSpacing;
            const wave = Math.sin(x * 0.05 + t + Math.PI) * 0.5; // Phase shifted
            const barHeight = maxBarHeight * (0.5 + wave * 0.5); // Adjusted calculation

            ctx.beginPath();
            ctx.moveTo(x, height);
            ctx.lineTo(x, height - barHeight);
            ctx.stroke();
        }

        ctx.restore();
        ctx.shadowBlur = 0;
    }

    /**
     * Draws text elements that float across the screen, pulsing with the music.
     */
    function drawMoodCloud() {
        if (!analyser) return;

        const width = viewWidth;
        const height = viewHeight;
        const amp = config.maxAmplitude;

        ctx.save();
        ctx.translate(offsetX, offsetY);
        ctx.textAlign = 'center';
        ctx.font = 'bold 24px Inter';
        ctx.shadowBlur = 8;

        for (let el of moodElements) {
            // Update position (normalized)
            el.x += el.vx;
            el.y += el.vy;

            // Apply spin (Rotation speed is amplified by audio amplitude)
            el.rotation += el.rotationSpeed * (1 + amp * 5);

            // Simple boundary bounce
            if (el.x > 0.95 || el.x < 0.05) el.vx *= -1;
            if (el.y > 0.95 || el.y < 0.05) el.vy *= -1;

            // Opacity smoothing and pulsing
            const targetAmpOpacity = amp * 0.8;
            el.targetOpacity = Math.max(0.2, targetAmpOpacity); // Minimum visibility
            el.opacity += (el.targetOpacity - el.opacity) * 0.1; // Smooth transition

            // Draw
            const hue = (frameCount * 0.3 + el.x * 100) % 360;
            const lightness = 70 + amp * 20; // Brighter with music

            ctx.globalAlpha = el.opacity;
            ctx.fillStyle = `hsl(${hue}, 100%, ${lightness}%)`;
            ctx.shadowColor = `hsl(${hue}, 100%, 50%)`;

            const drawX = el.x * width;
            const drawY = el.y * height;

            // --- Apply Rotation Transformation ---
            ctx.save();
            ctx.translate(drawX, drawY);
            ctx.rotate(el.rotation);
            // Draw text at the new local origin (0, 0)
            ctx.fillText(el.text, 0, 0);
            ctx.restore();
            // ------------------------------------
        }

        ctx.restore();
        ctx.shadowBlur = 0;
        ctx.globalAlpha = 1.0;
    }


    // --- Main Animation Loop ---

    /**
     * Checks if a resize is needed and recalculates 16:9 view area.
     */
    function resizeCanvas() {
        if (canvas.width !== window.innerWidth || canvas.height !== window.innerHeight) {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        } else {
            return; // No change, skip expensive resizing
        }

        const screenRatio = canvas.width / canvas.height;

        let calculatedWidth, calculatedHeight; // Temp variables for initial fit

        if (screenRatio > aspectRatio) {
            // Screen is wider than 16:9 (constrained by height)
            calculatedHeight = canvas.height;
            calculatedWidth = calculatedHeight * aspectRatio;
        } else {
            // Screen is taller than 16:9 (constrained by width)
            calculatedWidth = canvas.width;
            calculatedHeight = calculatedWidth / aspectRatio;
        }

        // --- Apply 5% Overscan (1.05 multiplier) ---
        const overscanFactor = 1.05;
        viewWidth = calculatedWidth * overscanFactor;
        viewHeight = calculatedHeight * overscanFactor;

        // Recalculate offsets to center the *overscanned* area
        offsetX = (canvas.width - viewWidth) / 2;
        offsetY = (canvas.height - viewHeight) / 2;
    }

    // Use a dedicated resize listener instead of checking every frame
    window.addEventListener('resize', resizeCanvas);


    /**
     * Main rendering loop, running at native monitor refresh rate (typically 60 FPS).
     */
    function animate() {
        if (isRunning) {
            // Audio analysis must happen first and fast
            updateAudioAnalysis();

            // 1. Draw low-res plasma to temp canvas
            drawPlasma();

            // Clear canvas once (clears the whole screen area)
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const drawCenterX = offsetX + viewWidth / 2;
            const drawCenterY = offsetY + viewHeight / 2;

            const baseFisheyeScale = 1.5; // Base Fisheye distortion
            let finalPlasmaScale = baseFisheyeScale;

            // --- 2. Calculate Dynamic Tunnel Depth Scale (NEW LOGIC) ---
            if (activeEffects.tunnel) {
                const amp = config.maxAmplitude;
                const t = frameCount * 0.01;
                // Modulate the scale based on audio and time for a pulsating depth effect.
                // This creates the stable, non-glitchy 3D tunnel look.
                finalPlasmaScale = baseFisheyeScale * (1.0 + amp * 0.2 + Math.sin(t * 0.5) * 0.05);
            }

            // --- START FULL ROTATION BLOCK ---
            if (activeEffects.rotation) {

                globalRotation += ROTATION_STEP;

                ctx.save();
                ctx.translate(drawCenterX, drawCenterY);
                ctx.rotate(globalRotation);

                // --- Dynamic Ambient Color Fill ---
                const rotationHue = (frameCount * 0.5) % 360;
                const rotationLightness = 5 + (config.maxAmplitude * 10);
                const rotationColor = `hsl(${rotationHue}, 100%, ${rotationLightness}%)`;
                // ----------------------------------

                // --- FIX: Fill area larger than diagonal BEFORE restoring translate ---
                // This ensures the exposed corners are covered by a dynamic, rotating fill.
                const diagonal = Math.sqrt(viewWidth * viewWidth + viewHeight * viewHeight);
                ctx.fillStyle = rotationColor;
                ctx.fillRect(-diagonal / 2, -diagonal / 2, diagonal, diagonal);
                // --------------------------------------------------------------------------

                ctx.translate(-drawCenterX, -drawCenterY);
            }
            // ---------------------------------

            // --- 3. Draw Plasma with Combined Fisheye/Tunnel Scale (GPU-Accelerated) ---
            ctx.save();

            // Apply Combined Scale (Fisheye + Tunnel Depth)
            ctx.translate(drawCenterX, drawCenterY);
            ctx.scale(finalPlasmaScale, finalPlasmaScale);
            ctx.translate(-drawCenterX, -drawCenterY);

            // Draw the low-res plasma image into the scaled/overscanned view area
            ctx.drawImage(tempCanvas, offsetX, offsetY, viewWidth, viewHeight);

            ctx.restore(); // Restore Scale

            // --- 4. Draw Overlays (Drawn on top of the rotated/scaled plasma) ---
            if (activeEffects.circles) {
                drawCircularWaves();
            }
            if (activeEffects.analyzer) {
                drawSpectrograph();
            }
            if (activeEffects.hgrid) { // NEW
                drawHorizontalPulseGrid();
            }
            if (activeEffects.flash) {
                drawCornerFlash();
            }
            if (activeEffects.scope) {
                drawOscilloscope();
            }
            if (activeEffects.moodcloud) {
                drawMoodCloud();
            }

            // --- END FULL ROTATION BLOCK ---
            if (activeEffects.rotation) {
                ctx.restore(); // Restore the rotation state
            }

            frameCount++;

            requestAnimationFrame(animate);
        }
    }

    // Initial setup on load
    window.addEventListener('load', () => {
        resizeCanvas();

        // Apply loaded state to UI checkboxes
        for (const key in activeEffects) {
            const elementId = `toggle${key.charAt(0).toUpperCase() + key.slice(1)}`;
            const checkbox = document.getElementById(elementId);
            if (checkbox) {
                checkbox.checked = activeEffects[key];
            }
        }
    });

</script>
</body>
</html>
